"""
Phase 3: ê¸°ì¡´ í”¼ì²˜ í´ë˜ìŠ¤ë¥¼ ìœ„í•œ API ìµœì í™” ë˜í¼

ì´ ëª¨ë“ˆì€ ê¸°ì¡´ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í´ë˜ìŠ¤ë“¤ì´ ìƒˆë¡œìš´ API ìµœì í™” ê¸°ëŠ¥ì„
íˆ¬ëª…í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë˜í•‘í•©ë‹ˆë‹¤.
"""

import logging
from typing import Dict, List, Any, Optional, Type
from datetime import datetime, timedelta
import pandas as pd
from .api_optimizer import APIOptimizer, APIRequest, APIResponse

logger = logging.getLogger(__name__)


class OptimizedFeatureWrapper:
    """í”¼ì²˜ í´ë˜ìŠ¤ë¥¼ ìœ„í•œ API ìµœì í™” ë˜í¼"""

    def __init__(self, feature_instance, api_optimizer: APIOptimizer):
        """
        Args:
            feature_instance: ê¸°ì¡´ í”¼ì²˜ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
            api_optimizer: API ìµœì í™” ê´€ë¦¬ì
        """
        self.feature = feature_instance
        self.optimizer = api_optimizer
        self._original_api_client = None

        # ê¸°ì¡´ API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìµœì í™”ëœ ë²„ì „ìœ¼ë¡œ êµì²´
        self._wrap_api_client()

        logger.info(
            f"ğŸ”§ Optimized wrapper applied to {type(feature_instance).__name__}"
        )

    def _wrap_api_client(self):
        """ê¸°ì¡´ API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìµœì í™”ëœ ë²„ì „ìœ¼ë¡œ ë˜í•‘"""
        if hasattr(self.feature, "api_client"):
            self._original_api_client = self.feature.api_client

            # API í´ë¼ì´ì–¸íŠ¸ì˜ request ë©”ì†Œë“œë¥¼ ìµœì í™”ëœ ë²„ì „ìœ¼ë¡œ êµì²´
            original_request = self._original_api_client.request

            def optimized_request_wrapper(method: str, api_name: str, **kwargs):
                """ìµœì í™”ëœ API ìš”ì²­ ë˜í¼"""
                try:
                    # API ìµœì í™”ê¸°ë¥¼ í†µí•´ ìš”ì²­ ìˆ˜í–‰
                    response = self.optimizer.optimized_request(
                        api_name=api_name,
                        method=method,
                        tr_id=kwargs.get("tr_id"),
                        params=kwargs.get("params"),
                        body=kwargs.get("body"),
                        headers=kwargs.get("headers"),
                    )

                    return response.data

                except Exception as e:
                    logger.warning(
                        f"Optimized request failed, falling back to original: {e}"
                    )
                    # ìµœì í™” ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë©”ì†Œë“œë¡œ í´ë°±
                    return original_request(method, api_name, **kwargs)

            # ë©”ì†Œë“œ êµì²´
            self.feature.api_client.request = optimized_request_wrapper

    def get_data(self, **kwargs) -> pd.DataFrame:
        """ìµœì í™”ëœ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            return self.feature.get_data(**kwargs)
        except Exception as e:
            logger.error(f"Optimized data collection failed: {e}")
            raise

    def save_to_csv(self, **kwargs) -> bool:
        """ìµœì í™”ëœ CSV ì €ì¥"""
        try:
            return self.feature.save_to_csv(**kwargs)
        except Exception as e:
            logger.error(f"Optimized CSV save failed: {e}")
            raise

    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        return self.optimizer.get_performance_report()

    def __getattr__(self, name):
        """ê¸°ì¡´ í”¼ì²˜ í´ë˜ìŠ¤ì˜ ëª¨ë“  ë©”ì†Œë“œë¥¼ íˆ¬ëª…í•˜ê²Œ ì „ë‹¬"""
        return getattr(self.feature, name)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # ì›ë³¸ API í´ë¼ì´ì–¸íŠ¸ ë³µì›
        if self._original_api_client and hasattr(self.feature, "api_client"):
            self.feature.api_client = self._original_api_client


class OptimizedDateRangeCollector:
    """ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ ìµœì í™”ëœ ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, api_optimizer: APIOptimizer):
        self.optimizer = api_optimizer

    def collect_futures_data_optimized(
        self,
        codes: List[str],
        start_date: datetime,
        end_date: datetime,
        api_name: str = "ì„ ë¬¼ì˜µì…˜ê¸°ê°„ë³„ì‹œì„¸(ì¼/ì£¼/ì›”/ë…„) [v1_êµ­ë‚´ì„ ë¬¼-008]",
        tr_id: str = "FHKIF03020100",
    ) -> Dict[str, pd.DataFrame]:
        """
        ì„ ë¬¼ ë°ì´í„°ë¥¼ ìµœì í™”ëœ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì§‘

        Args:
            codes: ì„ ë¬¼ ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            api_name: API ì´ë¦„
            tr_id: ê±°ë˜ ID

        Returns:
            Dict[str, pd.DataFrame]: ì½”ë“œë³„ ë°ì´í„°í”„ë ˆì„
        """
        results = {}
        total_api_calls = 0

        logger.info(
            f"ğŸ“Š Starting optimized futures data collection for {len(codes)} codes"
        )

        for code in codes:
            logger.info(f"ğŸ” Processing {code}...")

            # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •
            base_params = {
                "FID_COND_MRKT_DIV_CODE": "F",
                "FID_INPUT_ISCD": code,
                "FID_INPUT_DATE_1": "",  # ì‹œì‘ì¼ (ë™ì  ì„¤ì •)
                "FID_INPUT_DATE_2": "",  # ì¢…ë£Œì¼ (ë™ì  ì„¤ì •)
                "FID_PERIOD_DIV_CODE": "D",
            }

            try:
                # ìµœì í™”ëœ ë‚ ì§œ ë²”ìœ„ ìš”ì²­
                responses = self.optimizer.optimize_date_range_requests(
                    api_name=api_name,
                    code=code,
                    start_date=start_date,
                    end_date=end_date,
                    base_params=base_params,
                    date_param_name="FID_INPUT_DATE_1",
                    end_date_param_name="FID_INPUT_DATE_2",
                    tr_id=tr_id,
                )

                total_api_calls += len(responses)

                # ì‘ë‹µ ë°ì´í„° ë³‘í•©
                all_data = []
                for response in responses:
                    if response.data.get("rt_cd") == "0":
                        output_data = response.data.get("output2", [])
                        if output_data:
                            all_data.extend(output_data)
                    else:
                        logger.warning(
                            f"API error for {code}: {response.data.get('msg1', 'Unknown error')}"
                        )

                if all_data:
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì •ë¦¬
                    df = pd.DataFrame(all_data)
                    df = self._process_futures_dataframe(df)
                    results[code] = df

                    logger.info(f"âœ… {code}: {len(df)} records collected")
                else:
                    logger.warning(f"âš ï¸ No data collected for {code}")

            except Exception as e:
                logger.error(f"âŒ Failed to collect data for {code}: {e}")
                continue

        logger.info(
            f"ğŸ¯ Collection completed: {len(results)} codes, {total_api_calls} API calls"
        )
        return results

    def _process_futures_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì„ ë¬¼ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬"""
        if df.empty:
            return df

        try:
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            date_columns = ["stck_bsop_date", "bsop_date", "date"]
            date_col = None

            for col in date_columns:
                if col in df.columns:
                    date_col = col
                    break

            if date_col:
                df[date_col] = pd.to_datetime(
                    df[date_col], format="%Y%m%d", errors="coerce"
                )
                df = df.sort_values(date_col)
                df = df.drop_duplicates()

            # ìˆ«ìí˜• ì»¬ëŸ¼ ë³€í™˜
            numeric_columns = [
                "futs_prpr",
                "futs_oprc",
                "futs_hgpr",
                "futs_lwpr",
                "futs_clpr",
                "acml_vol",
                "acml_tr_pbmn",
                "futs_prdy_vrss",
            ]

            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")

            return df

        except Exception as e:
            logger.error(f"DataFrame processing error: {e}")
            return df


class OptimizedBatchCollector:
    """ë°°ì¹˜ ìµœì í™”ëœ ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, api_optimizer: APIOptimizer):
        self.optimizer = api_optimizer

    def collect_multiple_features_optimized(
        self, feature_configs: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ í”¼ì²˜ë¥¼ ë°°ì¹˜ë¡œ ìµœì í™” ìˆ˜ì§‘

        Args:
            feature_configs: í”¼ì²˜ ì„¤ì • ë¦¬ìŠ¤íŠ¸
                [
                    {
                        'feature_name': 'kospi200_futures_daily',
                        'api_name': '...',
                        'codes': ['101V06', '101V09'],
                        'params': {...}
                    },
                    ...
                ]

        Returns:
            Dict[str, Any]: í”¼ì²˜ë³„ ìˆ˜ì§‘ ê²°ê³¼
        """
        all_requests = []
        request_mapping = {}

        # ëª¨ë“  ìš”ì²­ ìƒì„±
        for config in feature_configs:
            feature_name = config["feature_name"]
            api_name = config["api_name"]
            codes = config.get("codes", [])
            base_params = config.get("params", {})

            for code in codes:
                params = base_params.copy()
                params.update(config.get("code_specific_params", {}).get(code, {}))

                request = APIRequest(
                    api_name=api_name, params=params, priority=config.get("priority", 5)
                )

                all_requests.append(request)
                request_mapping[id(request)] = {
                    "feature_name": feature_name,
                    "code": code,
                    "config": config,
                }

        logger.info(f"ğŸš€ Starting batch collection: {len(all_requests)} requests")

        # ë°°ì¹˜ ì‹¤í–‰
        responses = self.optimizer.batch_request(all_requests)

        # ê²°ê³¼ ì •ë¦¬
        results = {}
        for response in responses:
            mapping_info = request_mapping.get(id(response.request))
            if not mapping_info:
                continue

            feature_name = mapping_info["feature_name"]
            code = mapping_info["code"]

            if feature_name not in results:
                results[feature_name] = {}

            if response.data.get("rt_cd") == "0":
                results[feature_name][code] = {
                    "data": response.data.get("output2", []),
                    "success": True,
                    "response_time": response.response_time,
                    "cached": response.cached,
                }
            else:
                results[feature_name][code] = {
                    "data": [],
                    "success": False,
                    "error": response.data.get("msg1", "Unknown error"),
                    "response_time": response.response_time,
                }

        logger.info(f"âœ… Batch collection completed: {len(results)} features")
        return results


def apply_optimization_to_features(
    feature_instances: List[Any],
    api_client,
    optimization_config: Optional[Dict[str, Any]] = None,
) -> List[OptimizedFeatureWrapper]:
    """
    ì—¬ëŸ¬ í”¼ì²˜ ì¸ìŠ¤í„´ìŠ¤ì— ìµœì í™” ì ìš©

    Args:
        feature_instances: í”¼ì²˜ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        api_client: API í´ë¼ì´ì–¸íŠ¸
        optimization_config: ìµœì í™” ì„¤ì •

    Returns:
        List[OptimizedFeatureWrapper]: ìµœì í™”ëœ í”¼ì²˜ ë˜í¼ ë¦¬ìŠ¤íŠ¸
    """
    config = optimization_config or {}

    # API ìµœì í™”ê¸° ìƒì„±
    optimizer = APIOptimizer(
        api_client=api_client,
        max_requests_per_minute=config.get("max_requests_per_minute", 60),
        cache_ttl_seconds=config.get("cache_ttl_seconds", 300),
        max_workers=config.get("max_workers", 3),
    )

    # í”¼ì²˜ë“¤ì— ìµœì í™” ì ìš©
    optimized_features = []
    for feature_instance in feature_instances:
        optimized_wrapper = OptimizedFeatureWrapper(feature_instance, optimizer)
        optimized_features.append(optimized_wrapper)

    logger.info(f"ğŸ¯ Applied optimization to {len(optimized_features)} features")
    return optimized_features
