# -*- coding: utf-8 -*-
"""
êµ­ë‚´ ì„ ë¬¼/ì˜µì…˜ ì‹œì„¸ ë° ë¯¸ê²°ì œì•½ì • ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í”¼ì²˜ ëª¨ë“ˆ.
'ì„ ë¬¼ì˜µì…˜ê¸°ê°„ë³„ì‹œì„¸(ì¼/ì£¼/ì›”/ë…„) [v1_êµ­ë‚´ì„ ë¬¼-008]' APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì§€ì› ì‹œì¥:
- ì§€ìˆ˜ì„ ë¬¼(F)
- ìƒí’ˆì„ ë¬¼(ê¸ˆ, CF)
- ê¸ˆë¦¬ì„ ë¬¼(êµ­ì±„, CF)
- í†µí™”ì„ ë¬¼(ë‹¬ëŸ¬, CF)
- ì•¼ê°„ì„ ë¬¼(CM)
- ì•¼ê°„ì˜µì…˜(EU)
"""

import logging
from typing import Dict, List, Any, Optional, Union
import pandas as pd
from datetime import datetime, timedelta
import time

from src.feature_engineering.abstract_feature import Feature
from src.data_collection.api_client import APIClient

logger = logging.getLogger(__name__)


class DomesticFuturesPrice(Feature):
    """
    êµ­ë‚´ ì„ ë¬¼/ì˜µì…˜ ì‹œì„¸ ë° ë¯¸ê²°ì œì•½ì • ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ê´€ë¦¬í•˜ëŠ” í”¼ì²˜.

    - `features.yaml` ì„¤ì •ì„ í†µí•´ ì¡°íšŒí•  ì¢…ëª© ì½”ë“œ(`code_list`), ì‹œì¥ êµ¬ë¶„(`market_code`),
      ì¡°íšŒ ì£¼ê¸°(`inquiry_time_list`), ì¡°íšŒ ê¸°ê°„ íƒ€ì…(`period_code`), API íŒŒë¼ë¯¸í„°(`params`) ë“±ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    - `_perform_inquiry` ë©”ì„œë“œë¥¼ í†µí•´ ì£¼ê¸°ì ìœ¼ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    - `call_feature` ë©”ì„œë“œë¥¼ í†µí•´ ì €ì¥ëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """

    API_NAME = "ì„ ë¬¼ì˜µì…˜ê¸°ê°„ë³„ì‹œì„¸(ì¼/ì£¼/ì›”/ë…„) [v1_êµ­ë‚´ì„ ë¬¼-008]"

    def __init__(
        self,
        _feature_name: str,
        _code_list: List[str],  # ì„ ë¬¼/ì˜µì…˜ ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        _feature_query: APIClient,
        _quote_connect: bool,
        _inquiry: bool,
        _inquiry_time_list: List[str],
        _inquiry_name_list: List[str],
        _params: Dict,
    ):
        """
        DomesticFuturesPrice ìƒì„±ì.

        Args:
            _feature_name (str): í”¼ì²˜ ì´ë¦„
            _code_list (List[str]): ì¡°íšŒí•  ì„ ë¬¼/ì˜µì…˜ ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            _feature_query (APIClient): API í´ë¼ì´ì–¸íŠ¸
            _quote_connect (bool): ì‹œì„¸ ì—°ê²° ì—¬ë¶€ (í˜„ì¬ ë¯¸ì‚¬ìš©)
            _inquiry (bool): ì¡°íšŒ ìˆ˜í–‰ ì—¬ë¶€
            _inquiry_time_list (List[str]): ì¡°íšŒ ì‹œê°„ ë¦¬ìŠ¤íŠ¸
            _inquiry_name_list (List[str]): ì¡°íšŒ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            _params (Dict): íŒŒë¼ë¯¸í„°
        """
        super().__init__(
            _feature_name,
            _code_list,
            _feature_query,
            _quote_connect,
            _inquiry,
            _inquiry_time_list,
            _inquiry_name_list,
            _params,
        )
        self.schema_name = "domestic_futures_price"  # ìŠ¤í‚¤ë§ˆ ì´ë¦„ ì„¤ì •
        self.futures_data = {}  # ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
        self._initialize_params()

    def _initialize_params(self):
        """í”¼ì²˜ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ë° ê¸°ë³¸ê°’ ì„¤ì •"""
        if not self.code_list:
            raise ValueError(
                f"Missing required 'code_list' for feature {self.feature_name}"
            )

        # ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ params.yamlì—ì„œ ê°€ì ¸ì˜´
        self.market_code = self.params.get("market_code")
        self.period_code = self.params.get("period_code")
        self.pagination_delay_sec = self.params.get("pagination_delay_sec", 1.0)
        self.max_days_per_request = self.params.get(
            "max_days_per_request", 90
        )  # í•œ ë²ˆì— ì¡°íšŒí•  ìµœëŒ€ ì¼ìˆ˜

    def _split_date_range(
        self, start_date: str, end_date: str, max_days: int = 90
    ) -> List[tuple]:
        """
        ë‚ ì§œ ë²”ìœ„ë¥¼ API ì œí•œ(100ê±´)ì— ë§ê²Œ ë¶„í• í•©ë‹ˆë‹¤.

        Args:
            start_date (str): ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
            max_days (int): í•œ ë²ˆì— ì¡°íšŒí•  ìµœëŒ€ ì¼ìˆ˜

        Returns:
            List[tuple]: (ì‹œì‘ë‚ ì§œ, ì¢…ë£Œë‚ ì§œ) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            start_dt = datetime.strptime(start_date, "%Y%m%d")
            end_dt = datetime.strptime(end_date, "%Y%m%d")

            date_ranges = []
            current_start = start_dt

            while current_start <= end_dt:
                current_end = min(current_start + timedelta(days=max_days - 1), end_dt)
                date_ranges.append(
                    (current_start.strftime("%Y%m%d"), current_end.strftime("%Y%m%d"))
                )
                current_start = current_end + timedelta(days=1)

            return date_ranges
        except Exception as e:
            self.log_error(f"ë‚ ì§œ ë²”ìœ„ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")
            return [(start_date, end_date)]

    def _perform_inquiry(self, clock: str):
        """
        ì„¤ì •ëœ ì‹œê°„ì— ë§ì¶”ì–´ ì§€ì •ëœ ì¢…ëª© ì½”ë“œë“¤ì˜ ì‹œì„¸ ë° ë¯¸ê²°ì œì•½ì • ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        100ê±´ ì œí•œì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‚ ì§œ ë²”ìœ„ë¥¼ ë¶„í• í•˜ì—¬ ì—°ì†ì¡°íšŒë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            clock (str): í˜„ì¬ ì‹œê° (HHMMSS).
        """
        self.log_warning(
            f"ğŸ“ˆ êµ­ë‚´ ì„ ë¬¼ì˜µì…˜ ì¼ë³„ ê°€ê²© ì—°ì†ì¡°íšŒ ì‹œì‘ - ì½”ë“œ: {self.code_list}, ê¸°ê°„: {self.start_date}~{self.end_date}"
        )

        # TR ID ì •ì˜
        tr_id = "FHKIF03020100"

        for index, code in enumerate(self.code_list):
            try:
                # ë‚ ì§œ ë²”ìœ„ë¥¼ ë¶„í• í•˜ì—¬ ì—°ì†ì¡°íšŒ ì¤€ë¹„
                date_ranges = self._split_date_range(
                    self.start_date, self.end_date, self.max_days_per_request
                )

                # ì¢…ëª©ë³„ ì „ì²´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ë¦¬ìŠ¤íŠ¸
                all_data_frames = []
                total_records = 0

                self.log_warning(
                    f"ğŸ“Š {code}: {len(date_ranges)}ê°œ êµ¬ê°„ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì¡°íšŒ ì‹œì‘"
                )

                for range_idx, (range_start, range_end) in enumerate(date_ranges):
                    try:
                        # API íŒŒë¼ë¯¸í„° ì„¤ì •
                        params = {
                            "FID_COND_MRKT_DIV_CODE": self.market_code,  # ì‹œì¥ êµ¬ë¶„ (í•„ìˆ˜)
                            "FID_INPUT_ISCD": code,  # ì¢…ëª©ì½”ë“œ (í•„ìˆ˜)
                            "FID_PERIOD_DIV_CODE": self.period_code,  # ê¸°ê°„ êµ¬ë¶„ (í•„ìˆ˜)
                            "FID_INPUT_DATE_1": range_start,  # ì¡°íšŒ ì‹œì‘ì¼ (í•„ìˆ˜)
                            "FID_INPUT_DATE_2": range_end,  # ì¡°íšŒ ì¢…ë£Œì¼ (í•„ìˆ˜)
                        }

                        self.log_debug(
                            f"{code} [{range_idx+1}/{len(date_ranges)}êµ¬ê°„]: {range_start}~{range_end} ì¡°íšŒ"
                        )

                        # API í˜¸ì¶œ
                        response = self.get_api(self.API_NAME, params, tr_id=tr_id)

                        # ì‘ë‹µ íŒŒì‹±
                        parsed_df = self.parse_api_response(self.API_NAME, response)

                        if parsed_df is not None and not parsed_df.empty:
                            all_data_frames.append(parsed_df)
                            total_records += len(parsed_df)
                            self.log_debug(
                                f"{code}: {range_idx+1}êµ¬ê°„ ì™„ë£Œ ({len(parsed_df)}ê±´, ëˆ„ì : {total_records}ê±´)"
                            )
                        else:
                            self.log_debug(f"{code}: {range_idx+1}êµ¬ê°„ ë°ì´í„° ì—†ìŒ")

                        # êµ¬ê°„ ê°„ ì§€ì—°
                        if (
                            range_idx < len(date_ranges) - 1
                            and self.pagination_delay_sec
                        ):
                            time.sleep(self.pagination_delay_sec)

                    except Exception as range_e:
                        self.log_error(
                            f"{code} {range_idx+1}êµ¬ê°„ ({range_start}~{range_end}) ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {range_e}"
                        )
                        continue

                # ëª¨ë“  êµ¬ê°„ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                if all_data_frames:
                    combined_data = pd.concat(all_data_frames, ignore_index=True)

                    # ì¤‘ë³µ ì œê±° ë° ë‚ ì§œìˆœ ì •ë ¬
                    if "stck_bsop_date" in combined_data.columns:
                        combined_data = combined_data.drop_duplicates(
                            subset=["stck_bsop_date"]
                        )
                        combined_data = combined_data.sort_values("stck_bsop_date")

                    # ë°ì´í„° ì €ì¥
                    self.futures_data[code] = combined_data
                    self.save_data_with_schema(
                        self.schema_name, code.lower(), combined_data
                    )

                    # ë°ì´í„° ë²”ìœ„ í™•ì¸
                    start_date_str = combined_data["stck_bsop_date"].min()
                    end_date_str = combined_data["stck_bsop_date"].max()

                    self.log_warning(
                        f"âœ… {code}: ì¼ë³„ ê°€ê²© ì—°ì†ì¡°íšŒ ì™„ë£Œ - {total_records}ê±´ ìˆ˜ì§‘ "
                        f"({start_date_str} ~ {end_date_str})"
                    )
                else:
                    self.log_warning(f"âš ï¸ {code}: ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

                # ë‹¤ìŒ ì¢…ëª© ì²˜ë¦¬ ì „ ì§€ì—°
                if index < len(self.code_list) - 1 and self.pagination_delay_sec:
                    time.sleep(self.pagination_delay_sec)

            except Exception as e:
                self.log_error(f"âŒ {code} ì—°ì†ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                import traceback

                self.log_error(traceback.format_exc())
                continue

        self.log_warning(
            f"ğŸ“ˆ êµ­ë‚´ ì„ ë¬¼ì˜µì…˜ ì¼ë³„ ê°€ê²© ì—°ì†ì¡°íšŒ ì™„ë£Œ (ì´ {len(self.code_list)}ê°œ ì¢…ëª©)"
        )
        self.health_check_value = (
            f"êµ­ë‚´ ì„ ë¬¼ì˜µì…˜ ì¼ë³„ ê°€ê²© ì—°ì†ì¡°íšŒ ì™„ë£Œ (ì‹œê°„: {clock})"
        )

    def parse_api_response(
        self, api_name: str, response_data: Dict
    ) -> Optional[pd.DataFrame]:
        """
        ì„ ë¬¼ì˜µì…˜ê¸°ê°„ë³„ì‹œì„¸ API ì‘ë‹µì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ íŒŒì‹±í•˜ì—¬ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        OHLC, ê±°ë˜ëŸ‰, ê±°ë˜ëŒ€ê¸ˆ, ë¯¸ê²°ì œì•½ì •ìˆ˜ëŸ‰, ë¯¸ê²°ì œì•½ì •ìˆ˜ëŸ‰ ì¦ê°ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            api_name (str): API ì´ë¦„ (ë°˜ë“œì‹œ self.API_NAMEê³¼ ë™ì¼í•´ì•¼ í•¨).
            response_data (Dict): API ì‘ë‹µ ì›ë³¸ ë”•ì…”ë„ˆë¦¬.

        Returns:
            Optional[pd.DataFrame]: íŒŒì‹±ëœ ë°ì´í„°í”„ë ˆì„ ë˜ëŠ” None.
        """
        # ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬ ì‚¬ìš©
        if not self.handle_api_error(response_data, api_name):
            return None

        # ê°œì„ ëœ ê³µí†µ íŒŒì‹± ë©”ì„œë“œ ì‚¬ìš©
        df = self.parse_api_basic(
            api_name=api_name,
            response_data=response_data,
            output_key="output2",
            date_column="stck_bsop_date",
            date_format="%Y%m%d",
            numeric_columns=[
                "futs_oprc",  # ì‹œê°€
                "futs_hgpr",  # ê³ ê°€
                "futs_lwpr",  # ì €ê°€
                "futs_prpr",  # í˜„ì¬ê°€/ì¢…ê°€
                "acml_vol",  # ê±°ë˜ëŸ‰
                "acml_tr_pbmn",  # ê±°ë˜ëŒ€ê¸ˆ
                "hts_otst_stpl_qty",  # ë¯¸ê²°ì œì•½ì • ìˆ˜ëŸ‰
                "otst_stpl_qty_icdc",  # ë¯¸ê²°ì œì•½ì • ìˆ˜ëŸ‰ ì¦ê°
            ],
        )

        if df is None:
            return None

        try:
            # output1ì—ì„œ ë¯¸ê²°ì œì•½ì • ë°ì´í„° ì¶”ì¶œ (ë‹¨ì¼ ê°’ìœ¼ë¡œ ëª¨ë“  í–‰ì— ë™ì¼í•˜ê²Œ ì ìš©)
            if "output1" in response_data and isinstance(
                response_data["output1"], dict
            ):
                output1 = response_data["output1"]
                hts_otst_stpl_qty = output1.get("hts_otst_stpl_qty")
                otst_stpl_qty_icdc = output1.get("otst_stpl_qty_icdc")

                if (
                    hts_otst_stpl_qty is not None
                    and "hts_otst_stpl_qty" not in df.columns
                ):
                    df["hts_otst_stpl_qty"] = hts_otst_stpl_qty
                if (
                    otst_stpl_qty_icdc is not None
                    and "otst_stpl_qty_icdc" not in df.columns
                ):
                    df["otst_stpl_qty_icdc"] = otst_stpl_qty_icdc

            # ë°ì´í„° ì •ë¦¬: í‘œì¤€ ì»¬ëŸ¼ë§Œ ìœ ì§€
            required_columns = [
                "stck_bsop_date",  # ê¸°ì¤€ì¼ì
                "futs_prpr",  # í˜„ì¬ê°€/ì¢…ê°€
                "futs_oprc",  # ì‹œê°€
                "futs_hgpr",  # ê³ ê°€
                "futs_lwpr",  # ì €ê°€
                "acml_vol",  # ê±°ë˜ëŸ‰
                "acml_tr_pbmn",  # ê±°ë˜ëŒ€ê¸ˆ
                "mod_yn",  # ìˆ˜ì •ì—¬ë¶€
            ]

            # ì„ íƒì  ì»¬ëŸ¼ë“¤ (ìˆìœ¼ë©´ í¬í•¨)
            optional_columns = [
                "hts_otst_stpl_qty",  # ë¯¸ê²°ì œì•½ì • ìˆ˜ëŸ‰
                "otst_stpl_qty_icdc",  # ë¯¸ê²°ì œì•½ì • ìˆ˜ëŸ‰ ì¦ê°
            ]

            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            final_columns = []
            for col in required_columns:
                if col in df.columns:
                    final_columns.append(col)

            for col in optional_columns:
                if col in df.columns:
                    final_columns.append(col)

            # ë‚ ì§œ ì»¬ëŸ¼ëª… í™•ì¸ ë° í‘œì¤€í™”
            date_column = None
            possible_date_columns = [
                "stck_bsop_date",
                "date",
                "bsop_date",
                "trad_date",
                "bas_date",
                "std_date",
                "prdy_date",
                "curr_date",
                "today_date",
            ]
            for possible_date_col in possible_date_columns:
                if possible_date_col in df.columns:
                    date_column = possible_date_col
                    break

            # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë‚ ì§œ ìƒì„± ì‹œë„
            if date_column is None and not df.empty:
                # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²ƒì€ ì •ìƒì ì¸ ìƒí™©ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ debug ë ˆë²¨ë¡œ ë³€ê²½
                self.log_debug(
                    f"ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ ë°ì´í„°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ì»¬ëŸ¼: {list(df.columns)}"
                )
                return None

            if date_column is None:
                self.log_error(f"ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {df.columns.tolist()}")
                return None

            # ë‚ ì§œ ì»¬ëŸ¼ëª…ì„ í‘œì¤€í™”
            if date_column != "stck_bsop_date":
                df = df.rename(columns={date_column: "stck_bsop_date"})

            # í•„ìˆ˜ ì»¬ëŸ¼ë“¤ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
            if "stck_bsop_date" not in df.columns or "futs_prpr" not in df.columns:
                self.log_error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë¨: {df.columns.tolist()}")
                return None

            # ì»¬ëŸ¼ ì •ë¦¬ëœ DataFrame ìƒì„±
            df = df[final_columns].copy()

            return df

        except Exception as e:
            import traceback

            self.log_error(f"Error parsing API response: {e}\n{traceback.format_exc()}")
            return None

    def call_feature(
        self,
        code: Optional[str] = None,
        **kwargs,
    ) -> Any:
        """
        ì €ì¥ëœ ì„ ë¬¼/ì˜µì…˜ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            code (Optional[str]): ì¡°íšŒí•  íŠ¹ì • ì¢…ëª© ì½”ë“œ. Noneì´ë©´ ëª¨ë“  ì¢…ëª©ì˜ ë°ì´í„° ë°˜í™˜.
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„° (í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨).

        Returns:
            pd.DataFrame or Dict[str, pd.DataFrame] or None:
            - codeê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ì½”ë“œì˜ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜.
            - codeê°€ Noneì¸ ê²½ìš° {ì½”ë“œ: ë°ì´í„°í”„ë ˆì„} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜.
            - ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° None ë°˜í™˜.
        """
        if code:
            if code in self.futures_data:
                return self.futures_data[code].copy()
            else:
                # ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸” ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ ì‹œë„
                data = self.get_data_with_schema(self.schema_name, code.lower())
                if data is not None:
                    self.futures_data[code] = data
                    return data
                self.log_warning(f"No data available for code {code}.")
                return None
        else:
            # ëª¨ë“  ì½”ë“œì˜ ë°ì´í„° ë°˜í™˜
            if not self.futures_data:
                # ì €ì¥ì†Œì—ì„œ ëª¨ë“  ì½”ë“œì˜ ë°ì´í„° ë¡œë“œ ì‹œë„
                for c in self.code_list:
                    data = self.get_data_with_schema(self.schema_name, c.lower())
                    if data is not None:
                        self.futures_data[c] = data

            return (
                {k: v.copy() for k, v in self.futures_data.items()}
                if self.futures_data
                else None
            )

    # @staticmethod
    # def calculate_moving_average(
    #     df: pd.DataFrame, window: int, price_col: str = "futs_prpr"
    # ) -> Optional[pd.Series]:
    #     """
    #     ê°€ê²© ë°ì´í„°ì— ëŒ€í•œ ì´ë™í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    #     Args:
    #         df (pd.DataFrame): ì‹œì„¸ ë°ì´í„°í”„ë ˆì„.
    #         window (int): ì´ë™í‰ê·  ìœˆë„ìš° í¬ê¸°.
    #         price_col (str): ì‚¬ìš©í•  ê°€ê²© ì»¬ëŸ¼ëª….

    #     Returns:
    #         pd.Series or None: ê³„ì‚°ëœ ì´ë™í‰ê·  ì‹œë¦¬ì¦ˆ ë˜ëŠ” ê³„ì‚° ì‹¤íŒ¨ ì‹œ None.
    #     """
    #     try:
    #         if price_col not in df.columns:
    #             logger.warning(f"Column '{price_col}' not found in DataFrame.")
    #             return None

    #         return df[price_col].rolling(window=window).mean()
    #     except Exception as e:
    #         logger.error(f"Error calculating moving average: {e}")
    #         return None

    # @staticmethod
    # def calculate_open_interest_momentum(
    #     df: pd.DataFrame, window: int = 5
    # ) -> pd.Series:
    #     """
    #     ë¯¸ê²°ì œì•½ì •ëŸ‰ì˜ ëª¨ë©˜í…€(ë³€í™”ìœ¨)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    #     Args:
    #         df (pd.DataFrame): ë¯¸ê²°ì œì•½ì • ë°ì´í„°í”„ë ˆì„.
    #         window (int): ëª¨ë©˜í…€ ê³„ì‚°ì„ ìœ„í•œ ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 5).

    #     Returns:
    #         pd.Series: ë¯¸ê²°ì œì•½ì •ëŸ‰ ëª¨ë©˜í…€(Nì¼ê°„ ë³€í™”ìœ¨, %).
    #     """
    #     try:
    #         if "optr_opnt_qty" not in df.columns:
    #             logger.warning("Column 'optr_opnt_qty' not found in DataFrame.")
    #             return pd.Series(index=df.index)

    #         # ë¯¸ê²°ì œì•½ì •ëŸ‰ ë³€í™”ìœ¨ (%) ê³„ì‚°
    #         pct_change = df["optr_opnt_qty"].pct_change(periods=window) * 100
    #         return pct_change

    #     except Exception as e:
    #         logger.error(f"Error calculating open interest momentum: {e}")
    #         return pd.Series(index=df.index)
