#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
í”¼ì²˜ ë°ì´í„° ìˆ˜ì§‘ ë° CSV ì €ì¥ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

íŠ¹ì • í”¼ì²˜ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import sys
import yaml
import logging
import argparse
from datetime import datetime
from typing import Dict, List, Any, Optional
import pandas as pd
import traceback

# ë¡œê¹… ì„¤ì • - WARNING ë ˆë²¨ë¡œ ë³€ê²½í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ë§Œ ì¶œë ¥
current_date = datetime.now().strftime("%Y%m%d")
log_file = f"logs/data_collector_{current_date}.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)

logging.basicConfig(
    level=logging.WARNING,  # INFOì—ì„œ WARNINGìœ¼ë¡œ ë³€ê²½
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(log_file, encoding="utf-8"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)

# ê²½ë¡œ ì„¤ì •
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(script_dir))  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
if project_root not in sys.path:
    sys.path.append(project_root)

# í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸ (DB ê´€ë ¨ ì œê±°)
from src.feature_engineering.feature_manager import FeatureManager
from src.utils.trading_calendar import (
    get_current_trading_date,
    get_trading_session_info,
)


def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="í”¼ì²˜ ë°ì´í„° ìˆ˜ì§‘ ë° CSV ì €ì¥ ìŠ¤í¬ë¦½íŠ¸"
    )

    parser.add_argument(
        "--features",
        "-f",
        type=str,
        help="ìˆ˜ì§‘í•  í”¼ì²˜ ì´ë¦„ (ì‰¼í‘œë¡œ êµ¬ë¶„, ê¸°ë³¸ê°’: ëª¨ë“  í”¼ì²˜)",
        default=None,
    )

    parser.add_argument(
        "--time",
        "-t",
        type=str,
        help="ìˆ˜ì§‘ ì‹œê°„ (HHMMSS í˜•ì‹, ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°„)",
        default=datetime.now().strftime("%H%M%S"),
    )

    parser.add_argument(
        "--config",
        "-c",
        type=str,
        help="feature.yaml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
        default="config/features.yaml",
    )

    parser.add_argument(
        "--params",
        "-p",
        type=str,
        help="params.yaml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
        default="config/params.yaml",
    )

    parser.add_argument(
        "--api-config",
        "-a",
        type=str,
        help="api_config.yaml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
        default="config/api_config.yaml",
    )

    parser.add_argument(
        "--scheduled", "-s", action="store_true", help="ìŠ¤ì¼€ì¤„ëœ í”¼ì²˜ë§Œ ì‹¤í–‰"
    )

    parser.add_argument(
        "--test", action="store_true", help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ (CSV ì €ì¥ ì—†ìŒ)"
    )

    parser.add_argument(
        "--output-dir",
        "-o",
        type=str,
        help="CSV íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬",
        default="data",
    )

    return parser.parse_args()


def get_schema_name(feature_name: str) -> str:
    """í”¼ì²˜ ì´ë¦„ì—ì„œ ìŠ¤í‚¤ë§ˆ ì´ë¦„ ê²°ì •

    Args:
        feature_name: í”¼ì²˜ ì´ë¦„

    Returns:
        ìŠ¤í‚¤ë§ˆ ì´ë¦„
    """
    # íˆ¬ìì ë§¤ë§¤ë™í–¥ ë°ì´í„°ëŠ” ìš°ì„ ìˆœìœ„ ë†’ê²Œ ì²˜ë¦¬
    if "investor" in feature_name:
        return "market_data"
    elif "options" in feature_name:
        return "domestic_options"
    elif "futures" in feature_name and "overseas" in feature_name:
        return "overseas_futures"
    elif "futures" in feature_name:
        return "domestic_futures"
    else:
        return "sushi"


def combine_codes_data(data: Dict[str, Any]) -> pd.DataFrame:
    """ì—¬ëŸ¬ ì½”ë“œì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°

    Args:
        data: ì½”ë“œë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬

    Returns:
        í†µí•©ëœ DataFrame
    """
    combined_data = []

    for code, code_data in data.items():
        if code_data is None:
            continue

        # API ì‘ë‹µì—ì„œ DataFrame ì¶”ì¶œ
        if isinstance(code_data, dict) and "output2" in code_data:
            df = pd.DataFrame(code_data["output2"])
        elif isinstance(code_data, pd.DataFrame):
            df = code_data
        else:
            continue

        if df.empty:
            continue

        # ì½”ë“œ ì»¬ëŸ¼ ì¶”ê°€
        df["code"] = code
        combined_data.append(df)

    if combined_data:
        return pd.concat(combined_data, ignore_index=True)
    else:
        return pd.DataFrame()


def filter_investor_data(df: pd.DataFrame) -> pd.DataFrame:
    """íˆ¬ìì ë§¤ë§¤ë™í–¥ ë°ì´í„°ì—ì„œ ì™¸êµ­ì¸, ê¸°ê´€ ë°ì´í„°ë§Œ í•„í„°ë§

    Args:
        df: ì›ë³¸ DataFrame

    Returns:
        í•„í„°ë§ëœ DataFrame
    """
    # í•„ìš”í•œ ì»¬ëŸ¼ ì •ì˜ (ì™¸êµ­ì¸, ê¸°ê´€ ë°ì´í„°ë§Œ)
    essential_columns = [
        # ì™¸êµ­ì¸ ë°ì´í„°
        "frgn_seln_vol",
        "frgn_shnu_vol",
        "frgn_ntby_qty",
        "frgn_seln_tr_pbmn",
        "frgn_shnu_tr_pbmn",
        "frgn_ntby_tr_pbmn",
        # ê¸°ê´€ ë°ì´í„°
        "orgn_seln_vol",
        "orgn_shnu_vol",
        "orgn_ntby_qty",
        "orgn_seln_tr_pbmn",
        "orgn_shnu_tr_pbmn",
        "orgn_ntby_tr_pbmn",
    ]

    # ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ë“¤
    meta_columns = ["code", "trade_date", "collection_time"]

    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_columns = []
    for col in essential_columns:
        if col in df.columns:
            available_columns.append(col)

    for col in meta_columns:
        if col in df.columns:
            available_columns.append(col)

    return df[available_columns]


def get_csv_filename(feature_name: str, code: str) -> str:
    """í”¼ì²˜ëª…ê³¼ ì½”ë“œì— ë”°ë¥¸ ì ì ˆí•œ CSV íŒŒì¼ëª… ìƒì„±

    Args:
        feature_name: í”¼ì²˜ ì´ë¦„
        code: ì½”ë“œëª…

    Returns:
        CSV íŒŒì¼ëª…
    """
    # ì½œì˜µì…˜ íŠ¹ë³„ ì²˜ë¦¬
    if "call_investor" in feature_name and code == "options":
        return "calloptions.csv"
    # í’‹ì˜µì…˜ íŠ¹ë³„ ì²˜ë¦¬
    elif "put_investor" in feature_name and code == "putoptions":
        return "putoptions.csv"
    else:
        return f"{code}.csv"


def save_feature_to_csv(
    feature_name: str,
    data: Any,
    start_date: str,
    end_date: str,
    output_dir: str = "data",
) -> bool:
    """í”¼ì²˜ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥ (ì½”ë“œë³„ë¡œ ë¶„ë¦¬ ì €ì¥)

    Args:
        feature_name: í”¼ì²˜ ì´ë¦„
        data: í”¼ì²˜ ë°ì´í„°
        start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
        end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ìŠ¤í‚¤ë§ˆì™€ í”¼ì²˜ë³„ í´ë” ìƒì„±
        schema_name = get_schema_name(feature_name)
        feature_dir = os.path.join(output_dir, schema_name, feature_name)
        os.makedirs(feature_dir, exist_ok=True)

        saved_files = []

        if isinstance(data, dict):
            # ì½”ë“œë³„ë¡œ ê°œë³„ CSV íŒŒì¼ ì €ì¥
            for code, code_data in data.items():
                if code_data is None:
                    continue

                # API ì‘ë‹µì—ì„œ DataFrame ì¶”ì¶œ
                if isinstance(code_data, dict) and "output2" in code_data:
                    df = pd.DataFrame(code_data["output2"])
                elif isinstance(code_data, pd.DataFrame):
                    df = code_data
                else:
                    continue

                if df.empty:
                    continue

                # ì½”ë“œ ì»¬ëŸ¼ ì¶”ê°€
                df["code"] = code

                # ê±°ë˜ì¼ì ë° ìˆ˜ì§‘ ì‹œê°„ ì •ë³´ ì¶”ê°€
                current_time = datetime.now()
                df["trade_date"] = get_current_trading_date()
                df["collection_time"] = current_time.strftime("%H:%M:%S")

                # íˆ¬ìì ë§¤ë§¤ë™í–¥ ë°ì´í„°ì¸ ê²½ìš° í•„í„°ë§ ì ìš©
                if "investor" in feature_name:
                    df = filter_investor_data(df)

                # CSV íŒŒì¼ëª… ìƒì„± (ì½œì˜µì…˜ íŠ¹ë³„ ì²˜ë¦¬)
                csv_filename = get_csv_filename(feature_name, code)
                csv_path = os.path.join(feature_dir, csv_filename)

                # CSV ì €ì¥
                df.to_csv(csv_path, index=False, encoding="utf-8-sig")
                saved_files.append(csv_filename)

        elif isinstance(data, pd.DataFrame):
            # ë‹¨ì¼ DataFrameì¸ ê²½ìš°
            if not data.empty:
                # ê±°ë˜ì¼ì ë° ìˆ˜ì§‘ ì‹œê°„ ì •ë³´ ì¶”ê°€
                current_time = datetime.now()
                data["trade_date"] = get_current_trading_date()
                data["collection_time"] = current_time.strftime("%H:%M:%S")

                # íˆ¬ìì ë§¤ë§¤ë™í–¥ ë°ì´í„°ì¸ ê²½ìš° í•„í„°ë§ ì ìš©
                if "investor" in feature_name:
                    data = filter_investor_data(data)

                csv_filename = f"{feature_name}.csv"
                csv_path = os.path.join(feature_dir, csv_filename)
                data.to_csv(csv_path, index=False, encoding="utf-8-sig")
                saved_files.append(csv_filename)

        if saved_files:
            logger.warning(
                f"âœ… {feature_name}: {len(saved_files)}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ ({', '.join(saved_files[:3])}{'...' if len(saved_files) > 3 else ''})"
            )
            return True
        else:
            logger.warning(f"âš ï¸ {feature_name}: ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

    except Exception as e:
        logger.error(f"âŒ {feature_name} CSV ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False


def collect_and_save_data(
    features: Optional[List[str]] = None,
    time_str: Optional[str] = None,
    features_yaml_path: str = "config/features.yaml",
    params_yaml_path: str = "config/params.yaml",
    api_config_yaml_path: str = "config/api_config.yaml",
    scheduled_only: bool = False,
    test_mode: bool = False,
    output_dir: str = "data",
) -> None:
    """í”¼ì²˜ ë°ì´í„° ìˆ˜ì§‘ ë° CSV ì €ì¥

    Args:
        features: ìˆ˜ì§‘í•  í”¼ì²˜ ì´ë¦„ ëª©ë¡ (Noneì´ë©´ ëª¨ë“  í”¼ì²˜)
        time_str: ìˆ˜ì§‘ ì‹œê°„ (HHMMSS í˜•ì‹, Noneì´ë©´ í˜„ì¬ ì‹œê°„)
        features_yaml_path: features.yaml ì„¤ì • íŒŒì¼ ê²½ë¡œ
        params_yaml_path: params.yaml ì„¤ì • íŒŒì¼ ê²½ë¡œ
        api_config_yaml_path: api_config.yaml ì„¤ì • íŒŒì¼ ê²½ë¡œ
        scheduled_only: Trueì´ë©´ ìŠ¤ì¼€ì¤„ëœ í”¼ì²˜ë§Œ ì‹¤í–‰
        test_mode: Trueì´ë©´ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (CSV ì €ì¥ ì—†ìŒ)
        output_dir: CSV íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    try:
        os.makedirs("logs", exist_ok=True)
        if time_str is None:
            time_str = datetime.now().strftime("%H%M%S")

        # í•µì‹¬ ì •ë³´ë§Œ INFO ë ˆë²¨ë¡œ ì¶œë ¥
        logger.warning(
            f"ğŸš€ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: scheduled_only={scheduled_only}, test_mode={test_mode}"
        )

        feature_manager = FeatureManager(
            features_yaml_path=features_yaml_path,
            params_yaml_path=params_yaml_path,
            api_config_yaml_path=api_config_yaml_path,
        )

        # params.yamlì—ì„œ ë‚ ì§œ ë²”ìœ„ ì½ê¸°
        with open(params_yaml_path, "r", encoding="utf-8") as f:
            params_config = yaml.safe_load(f)

        features_to_get_data_from: Dict[str, Any] = {}

        if scheduled_only:
            logger.info(f"ìŠ¤ì¼€ì¤„ëœ í”¼ì²˜ ì²˜ë¦¬ ì‹œì‘: ì‹œê°„ {time_str}")
            all_managed_features = feature_manager.get_all_features()
            triggered_feature_names = []
            for name, feature_obj in all_managed_features.items():
                # Feature í´ë˜ìŠ¤ì˜ inquiry ë° inquiry_time_list ì†ì„± ì§ì ‘ ì‚¬ìš©
                if feature_obj.inquiry and time_str in feature_obj.inquiry_time_list:
                    try:
                        logger.info(f"'{name}' í”¼ì²˜ì— ëŒ€í•´ ìŠ¤ì¼€ì¤„ëœ inquiry ì‹¤í–‰ ì¤‘...")
                        feature_obj.run(
                            clock=time_str
                        )  # .run()ì´ _perform_inquiry í˜¸ì¶œ
                        features_to_get_data_from[name] = feature_obj
                        triggered_feature_names.append(name)
                    except Exception as e:
                        logger.error(
                            f"'{name}' í”¼ì²˜ì˜ ìŠ¤ì¼€ì¤„ëœ inquiry ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}",
                            exc_info=True,
                        )
            if triggered_feature_names:
                logger.info(
                    f"ìŠ¤ì¼€ì¤„ëœ inquiry ì‹¤í–‰ ì™„ë£Œ í”¼ì²˜: {', '.join(triggered_feature_names)}"
                )
            else:
                logger.info(f"{time_str}ì— ìŠ¤ì¼€ì¤„ëœ inquiryë¥¼ ì‹¤í–‰í•  í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # Not scheduled_only: Run specified or all features on-demand
            candidate_features_for_on_demand: Dict[str, Any] = {}
            if features:
                logger.info(
                    f"ì§€ì •ëœ í”¼ì²˜ë“¤ì— ëŒ€í•´ on-demand inquiry ì²˜ë¦¬ ì‹œì‘: {features}"
                )
                for feature_name_req in features:
                    feature_obj = feature_manager.get_feature(feature_name_req)
                    if feature_obj:
                        candidate_features_for_on_demand[feature_name_req] = feature_obj
                    else:
                        logger.warning(
                            f"FeatureManagerì—ì„œ '{feature_name_req}' í”¼ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
            else:
                logger.info("ëª¨ë“  í”¼ì²˜ì— ëŒ€í•´ on-demand inquiry ì²˜ë¦¬ ì‹œì‘")
                candidate_features_for_on_demand = feature_manager.get_all_features()

            if not candidate_features_for_on_demand:
                logger.info("On-demand inquiryë¥¼ ì‹¤í–‰í•  í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for name, feature_obj in candidate_features_for_on_demand.items():
                    try:
                        # On-demand ì‹¤í–‰ ì‹œ, í”¼ì²˜ì˜ inquiry í”Œë˜ê·¸ê°€ Trueì¸ ê²½ìš° _perform_inquiry ì§ì ‘ í˜¸ì¶œ
                        if feature_obj.inquiry:
                            if hasattr(feature_obj, "_perform_inquiry") and callable(
                                feature_obj._perform_inquiry
                            ):
                                logger.info(
                                    f"'{name}' í”¼ì²˜ì— ëŒ€í•´ on-demand _perform_inquiry ì‹¤í–‰ ì¤‘ (ì‹œê°„: {time_str})..."
                                )
                                feature_obj._perform_inquiry(clock=time_str)
                                features_to_get_data_from[name] = (
                                    feature_obj  # ë°ì´í„° ê°€ì ¸ì˜¬ í”¼ì²˜ ëª©ë¡ì— ì¶”ê°€
                                )
                            else:
                                logger.warning(
                                    f"'{name}' í”¼ì²˜ëŠ” inquiryê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ _perform_inquiry ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤."
                                )
                        else:
                            logger.info(
                                f"'{name}' í”¼ì²˜ëŠ” inquiryê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ on-demand inquiryë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
                            )
                    except Exception as e:
                        logger.error(
                            f"'{name}' í”¼ì²˜ì˜ on-demand _perform_inquiry ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}",
                            exc_info=True,
                        )

        logger.warning(
            f"ğŸ“Š ì´ {len(features_to_get_data_from)}ê°œì˜ í”¼ì²˜ì— ëŒ€í•´ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤."
        )

        success_count = 0
        failed_count = 0

        if test_mode:
            logger.warning("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: CSV íŒŒì¼ ì €ì¥ ì—†ì´ ë°ì´í„°ë§Œ í™•ì¸í•©ë‹ˆë‹¤.")

        for feature_name, feature in features_to_get_data_from.items():
            try:
                # í”¼ì²˜ë³„ ë‚ ì§œ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°
                feature_params = params_config.get(feature_name, {})
                start_date = feature_params.get("start_date", "20250101")
                end_date = feature_params.get("end_date", "20250531")

                # ë°ì´í„° ìˆ˜ì§‘
                data = feature.call_feature()

                if (
                    data is None
                    or (isinstance(data, pd.DataFrame) and data.empty)
                    or (isinstance(data, dict) and not data)
                ):
                    logger.warning(f"âš ï¸ {feature_name}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    failed_count += 1
                    continue

                if test_mode:
                    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë°ì´í„° ìš”ì•½ë§Œ ì¶œë ¥
                    if isinstance(data, dict):
                        logger.warning(
                            f"ğŸ” {feature_name}: {len(data)}ê°œ ì½”ë“œ ë°ì´í„° í™•ì¸ë¨"
                        )
                    elif isinstance(data, pd.DataFrame):
                        logger.warning(
                            f"ğŸ” {feature_name}: {len(data)}í–‰ ë°ì´í„° í™•ì¸ë¨"
                        )
                else:
                    # CSV ì €ì¥
                    if save_feature_to_csv(
                        feature_name, data, start_date, end_date, output_dir
                    ):
                        success_count += 1
                    else:
                        failed_count += 1

            except Exception as e:
                logger.error(f"âŒ {feature_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                failed_count += 1
        # ì™„ë£Œ ë©”ì‹œì§€
        if test_mode:
            logger.warning(
                f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì™„ë£Œ: {len(features_to_get_data_from)}ê°œ í”¼ì²˜ í™•ì¸ë¨"
            )
        else:
            logger.warning(
                f"ğŸ“ CSV ì €ì¥ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ"
            )
            if success_count > 0:
                logger.warning(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_dir}/ ë””ë ‰í† ë¦¬")

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)


# DB ê´€ë ¨ í•¨ìˆ˜ë“¤ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ CSV ì €ì¥ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()

    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í”¼ì²˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    features = args.features.split(",") if args.features else None

    collect_and_save_data(
        features=features,
        time_str=args.time,
        features_yaml_path=args.config,
        params_yaml_path=args.params,
        api_config_yaml_path=args.api_config,
        scheduled_only=args.scheduled,
        test_mode=args.test,
        output_dir=args.output_dir,
    )


if __name__ == "__main__":
    main()
